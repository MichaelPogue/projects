{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Gather information.\n",
    "Goals: gather basic channel data, gather initial single video data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules.\n",
    "import os\n",
    "import csv\n",
    "import schedule\n",
    "import pandas as pd\n",
    "from os import path\n",
    "from csv import writer\n",
    "from googleapiclient.discovery import build\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime\n",
    "\n",
    "# Set API parameters. \n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"API_KEY\")\n",
    "CHANNEL_ID = os.getenv(\"CHANNEL_ID\")\n",
    "youtube = build('youtube', 'v3', developerKey = API_KEY)\n",
    "\n",
    "# Primary function to get statistics.\n",
    "class ytStatsBase:\n",
    "    def __init__(self, API_KEY, CHANNEL_ID, youtube, channel_name):\n",
    "        self.API_KEY = API_KEY\n",
    "        self.CHANNEL_ID = CHANNEL_ID\n",
    "        self.youtube = youtube\n",
    "\n",
    "    # Get basic channel statistics.\n",
    "    def get_channel_statistics(self):\n",
    "        all_data = []\n",
    "        request = youtube.channels().list(\n",
    "            part = \"snippet,contentDetails,statistics\",\n",
    "            id = CHANNEL_ID\n",
    "            )\n",
    "        response = request.execute()\n",
    "\n",
    "        for i in range (len(response['items'])):\n",
    "            data = dict(\n",
    "                result_channel_name = response['items'][i]['snippet']['title'], \n",
    "                result_playlist_id = response['items'][i]['contentDetails']['relatedPlaylists']['uploads'],\n",
    "                result_channel_subscribers = response['items'][i]['statistics']['subscriberCount'], \n",
    "                result_channel_views = response['items'][i]['statistics']['viewCount'], \n",
    "                result_channel_total_videos = response['items'][i]['statistics']['videoCount'] \n",
    "                )\n",
    "            all_data.append(data)              \n",
    "        return all_data\n",
    "\n",
    "    # Get individual video IDs through playlist. \n",
    "    def get_video_ids(self):\n",
    "        playlist_id = ytStatsBase.get_channel_statistics(youtube)[0]['result_playlist_id']\n",
    "        \n",
    "        request = youtube.playlistItems().list(\n",
    "            part = 'contentDetails', \n",
    "            playlistId = playlist_id, \n",
    "            maxResults = 50\n",
    "        )\n",
    "        response = request.execute()\n",
    "\n",
    "        all_data = []\n",
    "\n",
    "        for i in range(len(response['items'])):\n",
    "            all_data.append(response['items'][i]['contentDetails']['videoId'])\n",
    "\n",
    "        next_page_token = response.get('nextPageToken')\n",
    "        more_pages = True\n",
    "\n",
    "        while more_pages:\n",
    "            if next_page_token is None:\n",
    "                more_pages = False\n",
    "            else:\n",
    "                request = youtube.playlistItems().list(\n",
    "                    part = 'contentDetails', \n",
    "                    playlistId = playlist_id, \n",
    "                    maxResults = 50, \n",
    "                    pageToken = next_page_token\n",
    "                )\n",
    "                response = request.execute()\n",
    "                \n",
    "                for i in range(len(response['items'])):\n",
    "                    all_data.append(response['items'][i]['contentDetails']['videoId'])\n",
    "                \n",
    "                next_page_token = response.get('nextPageToken')\n",
    "        \n",
    "        return all_data\n",
    "\n",
    "    # Get individual video details. \n",
    "    def get_video_details(self):\n",
    "        video_ids = ytStatsBase.get_video_ids(youtube)\n",
    "\n",
    "        all_data = []\n",
    "        for i in range(0, len(video_ids), 50):\n",
    "            request = youtube.videos().list(\n",
    "                part = 'snippet, statistics', \n",
    "                id = ','.join(video_ids[i: i + 50]),\n",
    "                #order = 'date' # Not possible or a feature at this time, 12Dec22.\n",
    "            )\n",
    "            response = request.execute()\n",
    "\n",
    "            for video in response['items']:\n",
    "                video_stats = dict(\n",
    "                    result_video_name = video['snippet']['title'],\n",
    "                    result_video_id = video['id'],                \n",
    "                    result_video_description = video['snippet']['description'],\n",
    "                    result_video_upload_time = video['snippet']['publishedAt'],\n",
    "                    result_video_views = video['statistics']['viewCount'],  \n",
    "                    result_video_likes = video['statistics']['likeCount'],  \n",
    "                    result_video_favorites = video['statistics']['favoriteCount'],  \n",
    "                    result_video_comments = video['statistics']['commentCount']  \n",
    "                    )\n",
    "                all_data.append(video_stats)\n",
    "        return all_data\n",
    "\n",
    "    # Transfer data into dataframes.\n",
    "    def create_data_frame(channel_stats, video_details):\n",
    "        # Create data frames.\n",
    "        initial_channel_data = pd.DataFrame(channel_stats, columns = [\n",
    "            'result_playlist_id',\n",
    "            'result_channel_name', \n",
    "            'result_channel_views',\n",
    "            'result_channel_subscribers',\n",
    "            'result_channel_total_videos' \n",
    "            ])\n",
    "        initial_video_data = pd.DataFrame(video_details, columns = [\n",
    "            'result_video_id',\n",
    "            'result_video_upload_time', \n",
    "            'result_video_name', \n",
    "            'result_video_description', \n",
    "            'result_video_views', \n",
    "            'result_video_likes', \n",
    "            'result_video_comments' \n",
    "            ])\n",
    "        return initial_channel_data, initial_video_data\n",
    "\n",
    "    # Generate personalized files.\n",
    "    def create_files(dfc, dfv):\n",
    "        # Create base files. \n",
    "        isExist1, isExist2 = os.path.exists(f'{channel_name}(channel_data).csv'), os.path.exists(f'{channel_name}(video_data).csv')\n",
    "        if isExist1 is True:\n",
    "            pass\n",
    "        elif isExist1 is False:\n",
    "            dfc.to_csv(f'{channel_name}(channel_data).csv')\n",
    "        if isExist2 is True:\n",
    "            pass\n",
    "        elif isExist2 is False:\n",
    "            dfv.to_csv(f'{channel_name}(video_data).csv')\n",
    "\n",
    "    # Gather new videos and append csv files.\n",
    "    def append_new_videos_data(dfv):\n",
    "        old_data = pd.read_csv(f'{channel_name}(video_data).csv', index_col=0)\n",
    "        new_data = (pd.concat([old_data, dfv])\n",
    "            .drop_duplicates([\"result_video_id\"], keep=False))\n",
    "        df = pd.concat([new_data, old_data], ignore_index=True)\n",
    "        df.to_csv(f'{channel_name}(video_data).csv')\n",
    "\n",
    "    # Gather new videos and append csv files.\n",
    "    def append_latest_statistics(dfv):\n",
    "        initial_test_data = pd.DataFrame(dfv, columns = [\n",
    "            'result_video_views',\n",
    "            'result_video_likes', \n",
    "            'result_video_comments'\n",
    "            ])\n",
    "        initial_test_data.insert(0,'date',pd.to_datetime('today').strftime(\"%y/%m/%d\"))\n",
    "        # return initial_test_data\n",
    "\n",
    "# Call functions.\n",
    "yt = ytStatsBase\n",
    "\n",
    "channel_stats, video_details = yt.get_channel_statistics(youtube), yt.get_video_details(youtube)\n",
    "channel_name = channel_stats[0]['result_channel_name']\n",
    "dfc, dfv = yt.create_data_frame(channel_stats, video_details)\n",
    "# yt.create_files(dfc, dfv)\n",
    "# yt.append_new_videos_data(dfv)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Write Information.\n",
    "Goals: Create two functions - one to append new videos and another to append updated statistics for trending. Both run 24/7 and appends once per day at a specific time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>result_video_id</th>\n",
       "      <th>result_video_upload_time</th>\n",
       "      <th>result_video_name</th>\n",
       "      <th>result_video_description</th>\n",
       "      <th>result_video_views</th>\n",
       "      <th>result_video_likes</th>\n",
       "      <th>result_video_comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fYyRzTirLN8</td>\n",
       "      <td>2022-12-24T21:00:11Z</td>\n",
       "      <td>When you live a life of never ending pain</td>\n",
       "      <td>It's Happy Wheels.\\n• Coffee - https://florida...</td>\n",
       "      <td>49092</td>\n",
       "      <td>5821</td>\n",
       "      <td>608</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  result_video_id result_video_upload_time  \\\n",
       "0     fYyRzTirLN8     2022-12-24T21:00:11Z   \n",
       "\n",
       "                           result_video_name  \\\n",
       "0  When you live a life of never ending pain   \n",
       "\n",
       "                            result_video_description result_video_views  \\\n",
       "0  It's Happy Wheels.\\n• Coffee - https://florida...              49092   \n",
       "\n",
       "  result_video_likes result_video_comments  \n",
       "0               5821                   608  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yt.create_files(dfc, dfv)\n",
    "yt.append_latest_statistics(dfv)\n",
    "dfv.head(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "863b3a55134ab839f8749329ac3d58c92f67b3b74d9daad2228f98af9c593ba4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
